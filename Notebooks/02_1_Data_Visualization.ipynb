{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"images/CI_horizontal.png\" width=\"600\">\n",
    "<center>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Website</a>\n",
    "    </span>\n",
    "</center>\n",
    "\n",
    "# Data Visualization in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, you will learn to quickly and flexibly generate a range of visualizations to explore data and communicate with your audience. This module contains a practical introduction to data visualization in Python and covers important rules to follow when creating visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Learn critical rules about data visualization (selecting graph types; labeling visual encodings; referencing data sources).\n",
    "\n",
    "* Become familiar with two core Python data visualization tools, `Matplotlib` and `seaborn`.\n",
    "\n",
    "* Start to develop the ability to conceptualize which visualizations can best reveal various types of patterns in your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Data Visualization Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "Matplotlib is always capitalized, like a typical proper noun.\n",
    "Seaborn is capitalized like an ordinary word, so it's lowercase if \"seaborn\" appears in the middle of a sentence.\n",
    "-->\n",
    "\n",
    "There are many excellent data visualization modules available in Python. You can read more about different options for data visualization in Python in the [More Resources](#More-Resources:) section at the bottom of this notebook. For this tutorial, you will stick to a tried and true combination of 2-D plotting libraries: `Matplotlib` and `seaborn`.\n",
    "\n",
    "`Matplotlib` is very expressive, meaning that it has functionality to allow extensive and fine-tuned creation of figures. It makes no assumptions about data, so it can be used to make historical timelines and fractals as well as bar charts. `Matplotlib`'s flexibility comes at the cost of additional complexity in its use. \n",
    "\n",
    "`Seaborn` is a higher-level module, trading some of the expressiveness and flexibility of matplotlib for more concise and easier syntax. For our purposes, `seaborn` improves on `Matplotlib` in several ways, making it easier to create small multiples, improving the color and aesthetics, and including direct support for some visualizations such as regression model results. `seaborn`'s creator, Michael Waskom, has compared the two:\n",
    "\n",
    "> If `Matplotlib` \"tries to make easy things easy and hard things possible, `seaborn` tries to make a well-defined set of hard things easy too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `seaborn` and `Matplotlib` together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may seem like we need to choose between these two approaches, but happily this is not the case. `seaborn` is itself written in `Matplotlib` (and you will sometimes see seaborn called a \"wrapper\" around `Matplotlib`). You can use `seaborn` to make graphs quickly,  then `Matplotlib` for specific adjustments. Whenever you see `plt` referenced in the code below, you are using a submodule of `Matplotlib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Set Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These abbreviations (pandas -> pd; seaborn -> sns) may seem arbitrary,\n",
    "# but they are community conventions that will help keep your work easy\n",
    "# to read and compare with that of other Python users.\n",
    "\n",
    "# pandas-related imports\n",
    "import pandas as pd\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# database interaction imports\n",
    "import sqlalchemy\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter-specific \"magic command\" to plot images directly in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Work with date\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to create a connection to the database, \n",
    "# we need to pass the name of the database and host of the database\n",
    "\n",
    "host = 'stuffed.adrf.info'\n",
    "DB = 'appliedda'\n",
    "\n",
    "connection_string = \"postgresql://{}/{}\".format(host, DB)\n",
    "conn = sqlalchemy.create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "In this notebook, we are going to tackle a series of questions provoked in the [Data Exploration](01_2_Data_Exploration.ipynb) notebook by using Ohio HEI data and Ohio and Indiana UI wage records. To answer them, you will be introduced to various visualizations which will provide a clearer view of the data than just using summary statistics and help you create powerful graphics that better convey the point(s) you want to make.\n",
    "\n",
    "The questions we will focus on this notebook are:\n",
    "- What is the distribution of earnings in Ohio during the first year after graduation for 2012-13 community college graduates? How does this differ by degree fields?\n",
    "- How have earnings in Ohio changed over time for 2012-13 community college graduates? How do one-year earnings differ by industry?\n",
    "- How do the degree fields of 2012-13 community college graduates differ across Ohio's regions?\n",
    "- What are the employment patterns of 2012-13 community college graduates one years after graduation? What are their cross-state movement patterns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Matplotlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will begin with some straightforward `Matplotlib` functions. First, you will start with some motivation questions, and then you will go on to use the appropriate `Matplotlib` commands to create your own visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When designing visualizations, it can help to just draw a sketch on paper first. Once you have an idea of what type of graph is best suited to illustrate the fact that you want to show, you should consider how to prepare the data for the graph. \n",
    "\n",
    "You can provide `Matplotlib` a `pandas` `DataFrame` or `Series`. You will want to ensure that the object includes exactly the information you want to plot because `Matplotlib` won't be doing much more than simple aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Histogram\n",
    "\n",
    "<font color=red> **Motivating Question #1**:</font>\n",
    "\n",
    "What is the distribution of earnings during the first year after graduation for 2012-13 community college graduates? How does this differ by degree fields?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since earnings is a numerical variable, you will want to use a visualization that can display a variety of numerical outputs on a continuous scale, such as a histogram. You will start by plotting a histogram of a single variable and customizing the figure. For a histogram, you will want to consider the scale -- whether you should plot everything or a subset of values. Plotting your data as a histogram makes it easier to quickly observe some features, such as the overall shape of the distribution and its skewness and kurtosis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Recall that in the Dataset Exploration notebook, we have created `cohort_oh_jobs` by joining the community college graduates table with the by quarter Ohio UI wage records. This table has the most recent degree record of each person and their UI wage records during the four quarters after graduation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = '''\n",
    "select *\n",
    "from ada_20_osu.cohort_oh_jobs\n",
    "'''\n",
    "df = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look at the table first.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The above DataFrame only has quarterly earnings. Let's use .groupby() to calculate the first year earnings\n",
    "earn_1y=df.groupby(['ssn_hash'])['sumwages'].agg('sum')\n",
    "\n",
    "earn_1y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earnings distribution of 2012-13 Ohio community college graduates \n",
    "# who have positive earnings during the first year after graduation\n",
    "earn_1y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "An easy way to get started with `Matplotlib` is to use its state-based interface, `matplotlib.pyplot`, which we have already imported above as `plt`. We can create a graph, then adjust its current state a bit at a time using `plt` functions.\n",
    "\n",
    "To create a new histogram, we'll simply pass our earning series into `plt.hist()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bare histogram of earnings distribution\n",
    "plt.hist(earn_1y)\n",
    "\n",
    "# The show() function outputs the current state of `pyplot`: our current fig.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from `.describe()` above already suggested a strong right skew, but this visualization shows us the distribution in much greater detail.\n",
    "\n",
    "Take a look at the earnings distribution. Do you need to make transformations to the earnings, such as topcode the outliers or use the log transformation of the earnings?\n",
    "\n",
    "Regardless, this is bare: let's at least add some labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(earn_1y)\n",
    "\n",
    "plt.ylabel('Count', fontsize='medium', labelpad=10)\n",
    "plt.xlabel('Earnings', fontsize='medium', labelpad=10)\n",
    "\n",
    "# In the notebook environment, the figure will automatically be\n",
    "# displayed if the Python code cell ends with an update to the plot,\n",
    "# so we can skip plt.show() in many cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Built-in styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "Now let's see how we can improve the style of this visualization. Every part of this figure can be customized in several ways, and `Matplotlib` includes several popular styles built-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Built-in style names:', ', '.join(sorted(plt.style.available)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the default style (affects font, color, positioning, and more)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.xlabel('Earnings', fontsize='medium', labelpad=10)\n",
    "plt.ylabel('Count', fontsize='medium', labelpad=10)\n",
    "\n",
    "# We need to replot the data in each newnotebook cell.\n",
    "plt.hist(earn_1y, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Style customization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "That's a bit better, but `Matplotlib` allows us to customize every individual component on the fly.\n",
    "\n",
    "> *How can you reset customizations?* In a notebook with multiple figures, you may want to reset everything before your next visualization. Or, having explored several options, you might want to undo all the stylistic tweaks without having to rerun the entire notebook. `matplotlib.rc_file_defaults()` will return just about everything to default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc_file_defaults()\n",
    "\n",
    "# Change the figure size -- let's make it big.\n",
    "plt.rc('figure', figsize=(8, 5))\n",
    "\n",
    "# Because `pyplot` works by incrementally updating the state of `plt`,\n",
    "# some changes must be made prior to creating those elements in the figure.\n",
    "# We'll make the axes spines (the box around the plot) invisible\n",
    "mpl.rc('axes', edgecolor='white', titlepad=20)\n",
    "\n",
    "# These will remove the axes ticks\n",
    "mpl.rc('xtick', bottom=False)\n",
    "mpl.rc('ytick', left=False)\n",
    "\n",
    "# Now we'll replot the data. Since the default is 10, but it seems like we can capture\n",
    "# more variation due to our sample size and distribution, let's try 50 bins.\n",
    "n_bins = 50\n",
    "plt.hist(earn_1y\n",
    "    , \n",
    "    bins=n_bins, \n",
    "    align='left',\n",
    "    color='xkcd:sage'\n",
    ")\n",
    "\n",
    "# Just after adding the data is a good time to remember to source it.\n",
    "plt.annotate(\n",
    "    'Sources: Ohio HEI data and UI wage record', \n",
    "    fontsize='x-small',\n",
    "    xycoords=\"figure fraction\", # specify x and y positions as % of the overall figure\n",
    "    xy=(1, 0.01), # 100% to the right (x) and 1% to the top (y) means bottom right\n",
    "    horizontalalignment='right', # the text will align appropriately for bottom right\n",
    ")\n",
    "\n",
    "# Add a title to the top of the figure\n",
    "plt.title(\"Earnings of 2012-13 Ohio Community College Graduates, First Year After Graduation\", fontsize='large')\n",
    "\n",
    "# Add axis labels, with a bit more padding than default between the label and the axes\n",
    "plt.xlabel('Earnings One Year Post-Graduation in Ohio', fontsize='medium', labelpad=10)\n",
    "plt.ylabel('Number of 2012-13 Graduates', fontsize='medium', labelpad=10)\n",
    "\n",
    "# Reduce the size of the axis labels\n",
    "plt.xticks(fontsize=9)\n",
    "plt.yticks(fontsize=9)\n",
    "\n",
    "# Add horizontal gridlines using negative space across the bars\n",
    "plt.grid(\n",
    "    color='white', \n",
    "    linewidth=1,\n",
    "    axis='y'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Data sourcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "A critical aspect of any data visualization intended for release is a reference to the source of the data being used. In these examples, we simply reference the agencies and names of the datasets. Whenever possible, we want to provide a direct path so that our audience can find the data we used to build the figure. When this is feasible  -- as with these restricted-access data -- be sure to direct the reader to documentation describing the data.\n",
    "\n",
    "Either way, providing clear sourcing for the underlying data is an absolute requirement of responsible dissemination. Transparent communication of sources and references builds trust between analyst and audience and helps enable the reproducibility of analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "toc-hr-collapsed": true
   },
   "outputs": [],
   "source": [
    "# If we're repeatedly doing the same kind of annotation, \n",
    "# it helps a lot to turn that into a function.\n",
    "def add_sourcing(plt, source_string, fontsize='x-small'):\n",
    "    \"\"\"Add small sourcing note to lower-right of current plot\n",
    "    \n",
    "    We would be using the same arguments over and over to do this.\n",
    "    So a quick function will make it simpler. Now we can simply:\n",
    "    \n",
    "    add_sourcing(plt, 'Sources: Ohio Longitudinal Data Archive')\n",
    "    \"\"\"\n",
    "    return plt.annotate(\n",
    "        source_string,\n",
    "        fontsize=fontsize,\n",
    "        xycoords=\"figure fraction\", # specify x and y positions as % of the overall figure\n",
    "        xy=(1, 0.01), # 100% to the right (x) and 1% to the top (y) means bottom right\n",
    "        horizontalalignment='right', # the text will align appropriately for bottom right    \n",
    "    )\n",
    "print(\"Now we can simply run:\\n   add_sourcing(plt, 'Text goes here')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple plots in one figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Matplotlib` is allowing you to make consecutive changes to the same plot, then display it whenever you are ready. The same process allows you to layer on multiple plots. By default, the first graph you create will be at the lowest layer, with each successive graph layered on top.\n",
    "\n",
    "To create these layered plots, you just need to run `plt.hist()` multiple times on different data frames. Then, as long as you provide the correct labels for your legend, you can run `plt.legend()` once to create a comprehensive legend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "<font color = red> <h2>Checkpoint #1: Histogram</h2></font>\n",
    "\n",
    "1. Plot a histogram for students who graduated during the spring semester. Recall that we have created a degree date variable, `deg_date`. For students who graduated in spring, `deg_date`=`2013-04-01`.\n",
    "\n",
    "2. Try to plot the histogram for autumn semester graduates on the same graph, i.e.: `deg_date`=`2012-10-01`.\n",
    "\n",
    "You'll definitely want to include:\n",
    "- A title (`plt.title`)\n",
    "- Axis labels (`plt.xlabel` and `plt.ylabel`)\n",
    "- Data sourcing (`plt.annotate` or the `add_sourcing` function defined above)\n",
    "\n",
    "If you use multiple colors (as you should with stacked histograms), you'll want to add a legend as well (`plt.legend`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Seaborn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Seaborn` provides a high-level interface to `Matplotlib`, which is powerful but sometimes unwieldy. `Seaborn` provides many useful defaults, so that we can quickly have:\n",
    "- More aesthetically pleasing defaults\n",
    "- A better range of color palettes\n",
    "- More complex graphs with less code\n",
    "- Small multiples (a sequence of small graphs in one figure)\n",
    "\n",
    "As you'll see, these libraries are complementary. Some tweaks will still require reaching back into `Matplotlib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar chart\n",
    "\n",
    "In this section, you will consider the differences in earnings for 2012-13 community college graduates in different degree fields. Recall that in the [Data Exploration](01_2_Dataset_Exploration.ipynb) notebook, you created two temporary tables:\n",
    "- `cc_grads`: all 2012-13 Ohio community college graduates. Some people have more than one record.\n",
    "- `cc_grads_recent`: only has the most recent degree record for each 2012-13 Ohio community college graduates\n",
    "\n",
    "You will recreate the same temporary table in this notebook, just this time using one query to create `cc_grads`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bar plot presents categorical data with rectangular bars proportional to the values that they represent. In this case, you will graph a horizontal bar plot. A bar plot represent an estimate of central tendency for a numeric variable with the length of each rectangle, and the `Seaborn` `barplot()` function also includes an indication of the uncertainty around the estimate using error bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cc_grads in one step\n",
    "qry = '''\n",
    "create temp table cc_grads as\n",
    "select a.*, lkp.*\n",
    "from data_ohio_olda_2018.oh_hei_long a\n",
    "left join data_ohio_olda_2018.oh_hei_campus_county_lkp lkp\n",
    "on a.degcert_campus = lkp.campus_num\n",
    "where ((a.degcert_yr_earned = '2012' and (a.degcert_term_earned = '4' or a.degcert_term_earned = '1')) or \n",
    "    (a.degcert_yr_earned = '2013' and (a.degcert_term_earned = '2' or a.degcert_term_earned = '3'))) and \n",
    "    lkp.campus_type_code in ('TC', 'SC', 'CC')\n",
    "'''\n",
    "conn.execute(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most recent graduation within the span of 2012-13 academic year\n",
    "# also get two-digit subject code\n",
    "qry = '''\n",
    "create temp table cc_grads_recent as\n",
    "select distinct on (ssn_hash) *, left(degcert_subject, 2) as subject\n",
    "from (\n",
    "SELECT *, \n",
    "    CASE WHEN degcert_term_earned = 4 THEN\n",
    "        format('%%s-%%s-01', degcert_yr_earned, 7)::date \n",
    "    WHEN degcert_term_earned = 1 THEN\n",
    "        format('%%s-%%s-01', degcert_yr_earned, 10)::date \n",
    "    WHEN degcert_term_earned = 2 THEN\n",
    "        format('%%s-%%s-01', degcert_yr_earned, 1)::date \n",
    "    WHEN degcert_term_earned = 3 THEN\n",
    "        format('%%s-%%s-01', degcert_yr_earned, 4)::date \n",
    "    END AS deg_date\n",
    "    from cc_grads\n",
    ") q\n",
    "order by ssn_hash, deg_date DESC\n",
    "'''\n",
    "conn.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in most_recent with two-digit subject code\n",
    "qry = '''\n",
    "select ssn_hash,subject from cc_grads_recent\n",
    "'''\n",
    "subject_df = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first ignore those with tr\n",
    "subject_df = subject_df[subject_df['subject'] != 'TR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Even when using the 2-digit subject code, you still have 38 degree fields. In this case, you can either group the degree fields into fewer categories or only show a few representative fields to the audience. Here, you will show the average earnings of students in the ten fields with the most graduates in 2012-13 academic year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just grabbing subject codes for 10 most popular subjects of graduates in this cohort \n",
    "subject_df.groupby(['subject'])['ssn_hash'].count().sort_values(ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select these subjects so we can subset most_recent and add the corresponding subject description\n",
    "# need to set as tuple so we can use .format() properly\n",
    "pop_subs = tuple(subject_df.groupby(['subject'])['ssn_hash'].count().sort_values(\n",
    "    ascending=False)[0:10].reset_index()['subject'])\n",
    "\n",
    "pop_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get everyone who graduated with a degree in one of the 10 most popular subjects along with\n",
    "# the year and term they graduated, as well as the corresponding subject description from the lookup table\n",
    "qry= '''\n",
    "select cc.ssn_hash, cc.deg_date, cc.subject, lkp.subject_desc \n",
    "from cc_grads_recent cc\n",
    "join data_ohio_olda_2018.oh_subject_codes_lkp lkp\n",
    "on cc.subject=lkp.subject_code_2010::varchar\n",
    "where cc.subject in {}\n",
    "limit 5\n",
    "'''.format(pop_subs)\n",
    "pd.read_sql(qry,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as temp table ten_subs\n",
    "qry= '''\n",
    "create temp table ten_subs as\n",
    "select cc.ssn_hash, cc.deg_date, cc.subject, lkp.subject_desc \n",
    "from cc_grads_recent cc\n",
    "join data_ohio_olda_2018.oh_subject_codes_lkp lkp\n",
    "on cc.subject=lkp.subject_code_2010::varchar\n",
    "where cc.subject in {}\n",
    "'''.format(pop_subs)\n",
    "conn.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have this, we can match it to the cohort_oh_jobs table because it already contains the earnings\n",
    "# for most recent graduation within this time\n",
    "qry = '''\n",
    "select distinct t.*, j.deg_date, j.sumwages\n",
    "from ten_subs t\n",
    "join ada_20_osu.cohort_oh_jobs j\n",
    "on j.ssn_hash = t.ssn_hash\n",
    "'''\n",
    "top_subs_wage = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_subs_wage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate each person's earnings during the first year after graduation\n",
    "df_by_ssn = top_subs_wage.groupby(['ssn_hash', 'subject_desc'])['sumwages'].agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now the table has each person's degree field and first year earnings\n",
    "#Recall that we only keep people who are in the TOP 10 fields with the most graduates\n",
    "df_by_ssn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-year earnings distribution by subject\n",
    "df_by_ssn.groupby('subject_desc')['sumwages'].agg(['describe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc_file_defaults() # reset most Matplotlib features to defaults\n",
    "\n",
    "plt.rc('figure', figsize=(15, 10))\n",
    "\n",
    "# By convention, a returned Axes object is often called `ax`\n",
    "ax = sns.barplot(\n",
    "    y=\"subject_desc\", # seaborn is clever enough to create a horizontal chart\n",
    "    x=\"sumwages\", \n",
    "    data=df_by_ssn, # order in data to order in figure\n",
    "    palette='vlag'\n",
    ")\n",
    "\n",
    "# We can use either `ax` or `plt` here; either will work\n",
    "add_sourcing(ax, 'Sources: Ohio HEI data and UI wage record')\n",
    "\n",
    "ax.set_title('First Year Earnings Varies Considerably Across Degree Fields')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> **Motivating Question #2**: </font>\n",
    "\n",
    "How have 2012-13 community college graduates' earnings changed over time in Ohio? \n",
    "\n",
    "We can use a line plot (`Seaborn` `lineplot()` function) for tracking change in a value over time (a time series graph). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a table for you `cohort_oh_wages_big` in the `ada_20_osu` schema that contains earnings by quarter over time for this cohort. To create this table, we used the entire `oh_ui_wage_by_quarter` table instead of `small_ohio_ui` when joining `cc_grads_recent` to the Unemployment Insurance wage records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = '''\n",
    "select * from ada_20_osu.cohort_oh_wages_big\n",
    "'''\n",
    "df_wages = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see table\n",
    "df_wages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert time_after_grad to quarters\n",
    "df_wages['quarter_after_grad']=(df_wages['time_after_grad']/90).round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by time after graduation (in days)\n",
    "df_by_ssn = df_wages.groupby(['ssn_hash', 'quarter_after_grad'])['sumwages'].agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_ssn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earnings by time after graduation\n",
    "df_by_ssn.groupby('quarter_after_grad')['sumwages'].agg(['describe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's adjust the nominal earnings to real earnings with a function\n",
    "def cpi_adj(year,wage):\n",
    "    \"\"\" Adjust annual earnings to 2017 dollars using\n",
    "        end of period CPI:\n",
    "    \"\"\"\n",
    "    ref = 247.847\n",
    "    if year == '2007':\n",
    "        return wage * ref/211.445\n",
    "    elif year == '2008':\n",
    "        return wage * ref/211.398\n",
    "    elif year == '2009':\n",
    "        return wage * ref/217.347\n",
    "    elif year == '2010':\n",
    "        return wage * ref/220.472\n",
    "    elif year == '2011':\n",
    "        return wage * ref/227.223\n",
    "    elif year == '2012':\n",
    "        return wage * ref/229.594\n",
    "    elif year == '2013':\n",
    "        return wage * ref/232.957\n",
    "    elif year == '2014':\n",
    "        return wage * ref/236.252\n",
    "    elif year == '2015':\n",
    "        return wage * ref/237.761\n",
    "    elif year == '2016':\n",
    "        return wage * ref/242.712\n",
    "    elif year == '2017':\n",
    "        return wage\n",
    "    else:\n",
    "        return 'CPI undefined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create the job year variable so that we can it in the function\n",
    "#The code below gives you the first four characters of `job_date`, which is the year of the job date\n",
    "df_wages['job_year']=df_wages['job_date'].astype(str).str[0:4]\n",
    "df_wages['job_year'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's adjust sumwages to its real value (2017 price level)\n",
    "df_wages['real_sumwages'] = df_wages.loc[:,('job_year', 'sumwages')].apply(lambda x: cpi_adj(*x), axis = 1).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_ssn = df_wages.groupby(['ssn_hash', 'quarter_after_grad'])['real_sumwages'].agg('sum').reset_index()\n",
    "df_by_ssn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: The title of a visualization occupies the most valuable real estate on the page. If nothing else, you can be reasonably sure a viewer will at least read the title and glance at your visualization. This is why you want to put thought into making a clear and effective title that acts as a **narrative** for your chart. It is best to avoid _explanatory_ titles, such as: \"Earnings of 2012-13 Ohio Community College Graduates Over Time\". This title is correct, yes -- but it isn't very useful. It is likely to be redundant, since \"earnings\" and \"time\" are probably labels on the axes already. Instead, use the title to reinforce and explain the core point of the visualization. It should answer the question **\"Why is this graph important?\"** and focus the viewer onto the most critical take-away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc_file_defaults() # reset most settings to defaults\n",
    "\n",
    "# A `with` statement (context manager) can be used to temporarily set figure styles\n",
    "with sns.axes_style('darkgrid'):\n",
    "    axes = sns.lineplot(data=df_by_ssn, x='quarter_after_grad', y='real_sumwages', color=\"#229900\")\n",
    "    axes.set_title('Anticipated Salary Has Been Increasing')\n",
    "    \n",
    "plt.xlabel('Quarters After Graduation')\n",
    "plt.ylabel('Real Quarterly Earnings')\n",
    "\n",
    "add_sourcing(plt, 'Sources: Ohio HEI data and UI wage records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small multiples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small multiples can be a great way to compare across categories, so that you can see several similarly plotted versions in the same overall figure. `Seaborn` offers an  easy interface for combining multiple plots into a single figure using the `FacetGrid` class. Because `FacetGrid` was designed for exactly this use, `seaborn` has helpful defaults such as automatically synchronized axes.\n",
    "\n",
    "You have looked at first year after graduation earnings over time; here, you will refocus on earnings one year post-graduation to see how earnings varies by employment fields (NAICS codes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in wages by employer table\n",
    "qry = '''\n",
    "select *\n",
    "from ada_20_osu.cohort_oh_jobs_emp emp\n",
    "join data_ohio_olda_2018.oh_naics3_codes_lkp lkp\n",
    "on emp.naics_3_digit=lkp.naics_3_digit_num\n",
    "'''\n",
    "df_emps = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see top 10 fields in this cohort\n",
    "df_emps.groupby(['naics_3_digit_label'])['ssn_hash'].count().sort_values(ascending=False).reset_index()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_naics = tuple(df_emps.groupby(['naics_3_digit_label'])['ssn_hash'].count().sort_values(ascending=False).reset_index()\n",
    "      [0:10]['naics_3_digit_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_naics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset df to only include those who found jobs in one of top_naics industries\n",
    "df_naics = df_emps[df_emps['naics_3_digit_label'].isin(top_naics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_ssn = df_naics.groupby(['ssn_hash', 'naics_3_digit_label'])['wages'].agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-year earnings distribution by naics\n",
    "df_by_ssn.groupby(['naics_3_digit_label'])['wages'].agg(['describe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare our grid, which will share axes across multiple plots (wrapping after 5 columns)\n",
    "g = sns.FacetGrid(df_by_ssn, col='naics_3_digit_label',col_wrap=5)\n",
    "\n",
    "# Create a lineplot for each cell of the grid\n",
    "g = g.map(plt.hist, \"wages\", color=\"lightcoral\")\n",
    "\n",
    "add_sourcing(plt, 'Source: Ohio HEI data and UI wage record', fontsize='medium')\n",
    "\n",
    "# Simplify the titles inside each cell\n",
    "g.set_titles(\"{col_name}\")\n",
    "\n",
    "# Remove the spine (vertical line) along the y axis\n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The colors used in figures in both `Matplotlib` and `seaborn` can be represented in code in many ways, but here are two naming conventions that `Matplotlib`, `seaborn`, and many other modern visualization packages handle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hex triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hex triplet is a specification for the RGB color model commonly used for website and browser-rendered colors. These are formatted as a string with a pound sign `#` followed by a series of six numbers. Each pair of hexadecimal digits (i.e., two of 0-9 and A-F) represents two bytes of color information for red, green, and blue, in that order: `\"#RRGGBB\"`. A low value (minimum 00) contributes less of that primary color, a high value (maximum FF) a larger amount. Together, these can specify over 16 million colors. An additional two hex digits can be added to indicate alpha (transparency) where 00 is completely transparent and FF is completely opaque. Hex triplets are very common across many platforms and packages well beyond data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XKCD names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A relatively new standard, XKCD names were the result of an online study crafted by Randall Monroe where volunteers entered free-form names of colors displayed on screen. Following the input of tens of thousands of participants, 954 common and distinguishing names were codified. Behind the scenes, these are still equivalent to specific hex triplets, but they can be more convenient. The result is a list of color names that many English speakers will find intuitive, from basics such as \"gold,\" \"green,\" and \"light grey\" to rarely-used terms. In `Matplotlib` and `seaborn`, these are written as a string prefixed by `xkcd:`, for example: `\"xkcd:cement\"` (#a5a391), `\"xkcd:pale magenta\"` (#d767ad), `\"xkcd:sage\"` (#87ae73), and `\"xkcd:green/blue\"` (#01c08d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "<font color = red><h2> Checkpoint #2: Small Multiples </h2></font>\n",
    "\n",
    "Trying using `sns.FacetGrid` in combination with a histogram, bar, or line chart.  Separating simple charts into several categories with small multiples can be a big improvement over trying to graph several things on the same chart.\n",
    "\n",
    "Try experimenting with color choices. Remember to add your source(s) and use a title that highlights the main conclusion.\n",
    "\n",
    "For example, you can explore the earnings distributions for community college students that graduated in different Ohio job regions (`jobsohioregion`). \n",
    "\n",
    "Hint: You will need the temporary table `cc_grads_recent` that you created earlier. You will also need the `cohort_oh_jobs` to get the quarterly earnings one year after graduation. Try to join these two tables first and consider what variables you should use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More visualization methods and motivating examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Heat map\n",
    "\n",
    "<font color=red> **Motivating Question #3:**</font>\n",
    "\n",
    "How do the degree fields of 2012-13 community college graduates differ across Ohio's regions?\n",
    "\n",
    "For something like this, we might want to use a heatmap. This can give a sort of visual summary similar to a crosstab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall the temp table ten_subs which subset our 2012-13 cohort for those who graduated with in one of the\n",
    "# 10 most popular subjects\n",
    "qry = '''\n",
    "select * \n",
    "from ten_subs \n",
    "limit 5\n",
    "'''\n",
    "pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to get jobsohioregion so can match back to cc_grads_recent\n",
    "qry = '''\n",
    "create temp table region as\n",
    "select t.*, cc.jobsohioregion\n",
    "from ten_subs t\n",
    "left join cc_grads_recent cc\n",
    "on t.ssn_hash = cc.ssn_hash and cc.deg_date = t.deg_date\n",
    "'''\n",
    "conn.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read into python\n",
    "qry = '''\n",
    "select * from region\n",
    "'''\n",
    "df_region = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job region breakdown\n",
    "df_region.groupby(['jobsohioregion'])['ssn_hash'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "toc-hr-collapsed": true
   },
   "outputs": [],
   "source": [
    "heatmap_df = pd.crosstab(df_region['subject_desc'], df_region['jobsohioregion'])\n",
    "\n",
    "ax = sns.heatmap(heatmap_df, cmap=sns.cubehelix_palette(light=1, as_cmap=True))\n",
    "add_sourcing(ax, 'Sources: Ohio Longitudinal Data Archive')\n",
    "\n",
    "# This heatmap fix is only necessary for 3.1.0 < Matplotlib <= 3.1.1; see https://stackoverflow.com/questions/56948670\n",
    "ax.set_ylim(len(heatmap_df), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Employment sequence chart\n",
    "\n",
    "<font color=red> **Motivating Question #4:**</font>\n",
    "\n",
    "What are the employment patterns of 2012-13 community college graduates one year after graduation? What are their cross-state movement patterns?\n",
    "\n",
    "To create a graphic that lets us answer this question, we need both time of graduation and quarterly earnings during the four quarters after graduation. In other words, we need to use both HEI data and UI wage records to create several dummy variables to indicate whether a person was employed during a quarter.\n",
    "\n",
    "In the following, we use the flexibility of pandas and these visualization libraries to create an unusual kind of chart. We will display the top ten most common patterns of employment in the time after a student receive his/her degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Conceptual design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "We have the idea, so we'll first want to think about what it will look like in the end, then work backwards to determine how we need to handle the data to create the table we'll need.\n",
    "\n",
    "It really helps to get concrete, particularly if you aren't doing a standard kind of figure. The final visualization we're aiming for will be organized something like this:\n",
    "\n",
    "```\n",
    "  employment pattern \n",
    "\n",
    "     - - - X | 11%\n",
    "     X X X X | 10%\n",
    "     X - X - | 9%\n",
    "     - - - X | 8%\n",
    "     - - X X | 7%    percent\n",
    "     - X X X | 6%    of sample\n",
    "     X X - - | 5%\n",
    "     X X - X | 4%\n",
    "     X X X - | 4%\n",
    "     - - - - | 4%\n",
    "    _________|\n",
    "    0     1\n",
    "      year\n",
    "\n",
    "```\n",
    "Each row is a pattern where an `X` indicates whether have positive earnings during that quarter and a `-` is no earnings in Ohio UI wages. If these were the real data, the first row would tell us that 11% of the 2012-13 community college graduates had positive and stable earnings in Ohio or Indiana in the fourth quarter after graduation. The second row shows 10% graduates had positive earnings in Ohio or Indiana immediately after graduation. The numbers here are arbitrary -- the point is to get a sense of what we're aiming for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've already done the analysis numerically in the Data Exploration notebook. Now, you need to visualize your findings in `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = '''\n",
    "select *\n",
    "from ada_20_osu.cohort_in_jobs\n",
    "limit 1\n",
    "'''\n",
    "pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = '''\n",
    "select *\n",
    "from ada_20_osu.cohort_oh_jobs\n",
    "limit 1\n",
    "'''\n",
    "pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp table of two job tables unioned\n",
    "qry = '''\n",
    "create temp table jobs_combined as \n",
    "select *, 'in' as state\n",
    "from ada_20_osu.cohort_in_jobs\n",
    "union\n",
    "select ssn_hash, deg_date, job_date, sumwages, , 'oh' as state \n",
    "from ada_20_osu.cohort_oh_jobs\n",
    "'''\n",
    "conn.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = '''\n",
    "select * from jobs_combined\n",
    "'''\n",
    "df_combined = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert time_after_grad to quarters\n",
    "df_combined['quarter_after_grad']=(df_combined['time_after_grad']/90).round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.groupby(['ssn_hash', 'quarter_after_grad'])['wages'].count().unstack(['quarter_after_grad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_combined.groupby(['ssn_hash', 'quarter_after_grad'])['wages'].count().unstack(['quarter_after_grad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN with 0\n",
    "df_tmp.fillna(0, inplace=True)\n",
    "\n",
    "# and set values >1 to 1\n",
    "df_tmp[df_tmp>1] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make ID value a column instead of an index - then we can count it when we group by the 'year_q' columns\n",
    "df_tmp.reset_index(inplace=True)\n",
    "df_tmp=df_tmp.rename(columns={1:'Q1',2:'Q2',3:'Q3',4:'Q4'})\n",
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by all columns to count number of people with the same pattern\n",
    "df_tmp.groupby(['Q1','Q2','Q3','Q4'])['ssn_hash'].count().reset_index().sort_values(by='ssn_hash', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the top 10 for a visualization\n",
    "df_tmp_top = df_tmp.groupby(['Q1','Q2','Q3','Q4'])['ssn_hash'].count().reset_index().sort_values(\n",
    "    by='ssn_hash', ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab for proportion calculations of total\n",
    "qry = '''\n",
    "select * from cc_grads_recent\n",
    "'''\n",
    "df = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate percentage of cohort in each group:\n",
    "df_tmp_top['pct_cohort'] = df_tmp_top['ssn_hash'].astype(float) / df['ssn_hash'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_viz = ['Q1','Q2','Q3','Q4']\n",
    "# visualize with a simple heatmap\n",
    "sns.heatmap(df_tmp_top[cols_for_viz],cmap=sns.cubehelix_palette(light=1, as_cmap=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default visualization leaves a lot to be desired. Now let's customize the same heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the matplotlib object so we can tweak graph properties later\n",
    "fig, ax = plt.subplots(figsize = (14,8))\n",
    "\n",
    "# create the list of labels we want on our y-axis\n",
    "ylabs = ['{:.2f}%'.format(x*100) for x in df_tmp_top['pct_cohort']]\n",
    "\n",
    "# make the heatmap\n",
    "sns.heatmap(df_tmp_top[cols_for_viz], linewidths=0.01, linecolor='grey', yticklabels=ylabs, cbar=False, cmap=\"Blues\")\n",
    "\n",
    "# make y-labels horizontal and change tickmark font size\n",
    "plt.yticks(rotation=360, fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "\n",
    "# add axis labels\n",
    "ax.set_ylabel('Percent of cohort', fontsize=16)\n",
    "ax.set_xlabel('Days since Graduation', fontsize=16)\n",
    "\n",
    "## Data Sourcing:\n",
    "ax.annotate('Source: Ohio HEI data, Ohio UI, and Indiana UI', \n",
    "            xy=(0.5,-0.15), xycoords=\"axes fraction\", fontsize=12)\n",
    "\n",
    "## add a title\n",
    "fig.suptitle('Top 10 most common employment patterns of cohort', fontsize=18)\n",
    "ax.set_title('Blue is \"employed\" and white is \"not employed\"', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "<font color = red><h2> Checkpoint #3: Compare with Indiana </h2></font>\n",
    "\n",
    "How do these employment patterns differ for those who found employment in Indiana?\n",
    "\n",
    "Hint: You can use the DataFrame you created above `df_combined` and limit the records to `df_combined['state']='in'`. Then follow the steps shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### `Matplotlib`\n",
    "\n",
    "* [Matplotlib Documentation](https://matplotlib.org)\n",
    "\n",
    "* [Matplotlib visualization tutorials](https://matplotlib.org/tutorials/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### `Seaborn`\n",
    "\n",
    "* [Seaborn Documentation](http://seaborn.pydata.org)\n",
    "\n",
    "* [Advanced Functionality in Seaborn](blog.insightdatalabs.com/advanced-functionality-in-seaborn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Colors\n",
    "\n",
    "Tools like [Adobe Color](https://color.adobe.com) and this [Hex Calculator](https://www.w3schoosl.com/colors/colors_hexadecimal.asp) can help you get used to the hex triplet system.\n",
    "\n",
    "The [official XKCD color list](https://xkcd.com/color/rgb/) lists all the named colors and their hex triplets; w3schools.com has also published an [XKCD color chart](https://www.w3schools.com/colors/colors_xkcd.asp) with larger swatches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Other Python Visualization Libraries\n",
    "\n",
    "[A Dramatic Tour through Python's Data Visualization Landscape](https://dsaber.com/2016/10/02/a-dramatic-tour-through-pythons-data-visualization-landscape-including-ggplot-and-altair) discusses and compares Matplotlib, seaborn, ggplot, and Altair.\n",
    "\n",
    "* [Plotly](https://plot.ly) focuses on interactive visualizations, including online hosting.\n",
    "\n",
    "* [Bokeh](http://bokeh.pydata.org) priotizes ease of use, also with an emphasis on in-browser, interactive charts.\n",
    "\n",
    "* [ggplot](http://ggplot.yhathq.com) is largely a port of R's heavily-used ggplot2 library, inspired by *The Grammar of Graphics*.\n",
    "\n",
    "* [Altair](https://altair-viz.github.io) is designed to be accessible and language independent, using the Vega-Lite syntax."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-ada",
   "language": "python",
   "name": "py3-ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
