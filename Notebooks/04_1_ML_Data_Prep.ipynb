{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"images/CI_horizontal.png\" width=\"1000\">\n",
    "<center>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Website</a>\n",
    "    </span>\n",
    "</center>\n",
    "\n",
    "Rayid Ghani, Frauke Kreuter, Julia Lane, Brian Kim, Adrianne Bradford, Alex Engler, Nicolas Guetta Jeanrenaud, Graham Henke, Daniela Hochfellner, Clayton Hunter, Avishek Kumar, Jonathan Morgan, Ursula Kaczmarek, Benjamin Feder, Ekaterina Levitskaya, Lina Osorio-Copete, Tian Lou."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for Clustering\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we will use Ohio Unemployment Insurance (UI) wage records to create an employer file, `employer_all_new.csv` and use it to run a clustering model in [Unsupervised Machine Learning](Unsupervised_ML.ipynb) notebook. We will focus on all the employers present in Ohio UI data during the third quarter of 2013 and create the following variables:\n",
    "\n",
    "- **Total employment**: number of paid employees each employer has during 2013Q3\n",
    "- **Total payroll**: the sum of wages an employer paid to all of its employees during 2013Q3\n",
    "- **Average payroll**: total payroll divided by total employment\n",
    "- **Earnings at the bottom 25th percentile**: the bottom 25% earnings within each employer during 2013Q3\n",
    "- **Earnings at the top  25th percentile**: the top 25% earnings within each employer during 2013Q3\n",
    "- **Total full quarter employees**: number of employees worked during 2013Q2, 2013Q3, and 2013Q4 within each employer\n",
    "- **Total payroll for full quarter employees**: the sum of wages an employer paid to all of its full quarter employees during 2013Q3\n",
    "- **Average payroll per full quarter employee**: total payroll for full quarter employees divided by total full quarter employees\n",
    "- **Separation growth rate**: percentage change in job separations within an employer from 2013Q2 to 2013Q3\n",
    "- **Hiring growth rate**: percentage change in new hires within an employer from 2013Q2 to 2013Q3\n",
    "- **Employment growth rate**: percentage change in an employer's size from 2013Q2 to 2013Q3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Setup\n",
    "First, let us run the cell below to import relevant libraries and establish our connection to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas-related imports\n",
    "import pandas as pd\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# database interaction imports\n",
    "import sqlalchemy\n",
    "\n",
    "# import viz \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import scipy.cluster.hierarchy as sch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to create a connection to the database, \n",
    "# we need to pass the name of the database and host of the database\n",
    "\n",
    "host = 'stuffed.adrf.info'\n",
    "DB = 'appliedda'\n",
    "\n",
    "connection_string = \"postgresql://{}/{}\".format(host, DB)\n",
    "conn = sqlalchemy.create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will take us a long time to run the code if we pull all the Ohio UI data from `data_ohio_olda_2018`. Therefore, we have created a subset of the `oh_ui_wage_by_employer` table, which only contains the data we need for this analysis (2013Q2-2013Q4 UI data) and for checkpoint (2013Q1). We call this table `oh_2013q3` and have saved it in schema `ada_20_osu`.\n",
    "\n",
    "The code used to generate the `oh_2013q3` table is available below.\n",
    "\n",
    "    create table ada_20_osu.oh_2013q3 as \n",
    "    select *, format('%%s-%%s-1', year, quarter*3-2)::date as job_yr_q\n",
    "    from data_ohio_olda_2018.oh_ui_wage_by_employer \n",
    "    where year = '2013';\n",
    "\n",
    "> We need information on employers from 2013Q2 and 2013Q4 to calculate full-quarter employment statistics, as well as hiring, employment, and separation rates.\n",
    "> In the checkpoints, you will be using 2013Q1-2013Q3 data to calculate the same statistics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore the Data\n",
    "\n",
    "Before we generate employer-level statistics, let's explore our table a little bit. This will give us some context about both the employers and the employees in the `oh_2013q3` table, as well as the overall labor market in Ohio.\n",
    "> Checking basic counts can also serve as a sanity check to make sure you properly subsetted your table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see table first\n",
    "qry = '''\n",
    "select * \n",
    "from ada_20_osu.oh_2013q3\n",
    "limit 5\n",
    "'''\n",
    "pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of distinct employers in table\n",
    "qry = '''\n",
    "select count(distinct(employer)) \n",
    "from ada_20_osu.oh_2013q3\n",
    "'''\n",
    "pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of distinct employers and employees with entries in 2013Q3\n",
    "qry = '''\n",
    "select count(distinct(employer)) as employer_num, count(distinct(ssn_hash)) as employee_num \n",
    "from ada_20_osu.oh_2013q3\n",
    "where quarter = 3 and year = '2013'\n",
    "'''\n",
    "pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of employers by quarter\n",
    "qry = '''\n",
    "select quarter, count(distinct(employer)) as employer_num\n",
    "from ada_20_osu.oh_2013q3\n",
    "group by quarter\n",
    "order by quarter\n",
    "'''\n",
    "pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 1: Sanity Check </h3></font> \n",
    "\n",
    "How many employees have earnings entries in 2013Q2? Does this number differ significantly from the amount of employees in 2013Q3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Employment and Earnings Statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment and Earnings of All Paid Employees within Each Employer\n",
    "Now that we have a better sense of the amount of employers and employees in 2013Q3, we can start to aggregate earnings and the number of employees by employer to generate our desired employer-level statistics. In this section, we will calculate: \n",
    "\n",
    "<il>\n",
    "<li>a. <b>Total employment</b>: <code>num_employed</code></li> \n",
    "<li>b. <b>Total payroll</b>: <code>total_earnings</code> </li>\n",
    "<li>c. <b>Average payroll</b>: <code>avg_earnings</code> </li>\n",
    "<li>d. <b>Earnings at the bottom 25 percentile</b>: <code>bottom_25_pctile</code> </li>\n",
    "<li>e. <b>Earnings at the top 25 percentile</b>: <code>top_25_pctile</code> </li>\n",
    "</il>  \n",
    "<p>\n",
    "     \n",
    "We can find this set of measures by only using 2013Q3 data and some simple manipulations. To find earnings percentiles, we just need to use `PERCENTILE_DISC() WITHIN GROUP (ORDER BY WAGES) AS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total earnings, number of employees, average earnigns, top 25% earnings, bottom 25% earnings\n",
    "#by employer in 2013Q3\n",
    "qry = '''\n",
    "select employer, naics_3_digit, count(ssn_hash) as num_employed, sum(wages) as total_earnings, \n",
    "    sum(wages)/count(ssn_hash) as avg_earnings, year, quarter,\n",
    "    percentile_disc(0.25) within group (order by wages) as bottom_25_pctile,\n",
    "    percentile_disc(0.75) within group (order by wages) as top_25_pctile\n",
    "from ada_20_osu.oh_2013q3\n",
    "where quarter = 3 and year = '2013'\n",
    "group by employer, naics_3_digit, year, quarter;\n",
    "'''\n",
    "employer_df = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see employer_df\n",
    "employer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment and Earnings of Full-Quarter Employees within Each Employer\n",
    "\n",
    "We define **full-quarter employees** as workers who have worked for the same employers during time *t-1*, *t*, and *t+1*. To find these workers, we will join three copies of the same `oh_2013q3` table with a SQL `WHERE` clause to confirm the person was employed in three consecutive quarters and worked for the same employer. In this case, we are looking at 2013Q2, 2013Q3, and 2013Q4 to determine if someone experienced full-quarter employment in 2013Q3. By aggregating on the employer level, we will find these measures: a. **number of full quarter employees**: `full_quarter_num`; b. **total payroll for full quarter employees**: `full_quarter_earnings`; c. **average earnings per full quarter employees**: `full_quarter_avg_earnings`.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of people who have worked for the same employer during 2013Q2, 2013Q3, and 2013Q4\n",
    "#The total wages each employer paid for full quarter employees\n",
    "#And the average earnings each employer paid for full quarter employeres\n",
    "qry = '''\n",
    "select a.employer, count(distinct(a.ssn_hash)) as full_quarter_num, sum(a.wages) as full_quarter_earnings, \n",
    "    sum(a.wages)/count(distinct(a.ssn_hash)) as full_quarter_avg_earnings\n",
    "from ada_20_osu.oh_2013q3 a, ada_20_osu.oh_2013q3 b, ada_20_osu.oh_2013q3 c\n",
    "where a.ssn_hash = b.ssn_hash and a.employer=b.employer and\n",
    "a.ssn_hash = c.ssn_hash and a.employer = c.employer and a.job_yr_q = (b.job_yr_q - '3 month'::interval)::date and \n",
    "a.job_yr_q = (c.job_yr_q + '3 month'::interval)::date \n",
    "group by a.employer\n",
    "'''\n",
    "\n",
    "full_quarter_df = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see full_quarter_df\n",
    "full_quarter_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 2: Generate Employment and Earnings Statistics for 2013Q2 Employers  </h3></font> \n",
    "\n",
    "Try to generate some employer-level characteristics for 2013Q2 employers:\n",
    "\n",
    "1. Calculate total employment, total payroll, average payroll, bottom 25% earnings, top 25% earnings for 2013Q2 employers. \n",
    "2. Calculate the number of full-quarter employees, total payroll for full-quarter employees, average earnings per full-quarter employee for 2013Q2 employers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Employment, Separation, and Hiring Growth Rates\n",
    "\n",
    "By looking at by employer UI data across quarters, we can observe the change in employment for each employer. In addition, since we know which person worked for which employer at what time, we can calculate how many workers left an employer during a quarter and how many new workers an employer hired during a quarter. \n",
    "\n",
    "However, should we directly use these numbers in our model? Probably not. The magnitude of job destructions and job creations largely depend on the size of a firm. Larger firms usually have larger numbers of job separations and new hires during each quarter than smaller firms, but it doesn't imply employment in larger firms are less stable. \n",
    "\n",
    "Therefore, we need to normalize the number of employment, the number of job separations, and the number of new hires so that employers of different sizes become more comparable with each other. We use the following function from <a href='https://academic.oup.com/qje/article-abstract/107/3/819/1873525'>Davis and Haltiwanger (1992)</a> to calculate 1) employment growth rate: `emp_rate`; 2) separation growth rate: `sep_rate`; 3) hire growth rate: `hire_rate`.\n",
    "\n",
    "$$ g_{et}=\\frac{2(x_{et} - x_{e,t-1})}{(x_{et} + x_{e,t-1})} $$\n",
    "\n",
    "In this function, $g_{et}$ represents employment/separation/hire growth rate of employer $e$ at time $t$. $x_{et}$ and $x_{e,t-1}$ are employer $e$'s employment/separation/hire at time $t$ and $t-1$, respectively. According to Davis and Haltiwanger (1992):\n",
    "\n",
    "\"*This growth rate measure is symmetric about zero, and it lies in the closed interval [-2,2] with deaths (births) corresponding to the left (right) endpoint. A virtue of this measure is that it facilitates an integrated treatment of births, deaths, and continuing establishments in the empirical analysis.*\"\n",
    "\n",
    "In other words, a firm with a $ g_{et} = 2$ is a new firm, while a firm with a $ g_{et} = -2$ is a a firm that exited the economy.\n",
    "    \n",
    "> Why do the two endpoints represent firms' deaths and births? Calculate the value of $g_{et}$ when $x_{et}=0$ and when $x_{e,t-1}=0$ and see what you get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment Growth Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the employment growth rate first. In the previous step, we have already calculated total number of employment within each employer in 2013Q3, `num_employed`. Here, we need to get the total number of employment within each employer in 2013Q2, `num_employed_q2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of employees during 2013Q2\n",
    "qry = '''\n",
    "select employer, count(ssn_hash) as num_employed_q2\n",
    "from ada_20_osu.oh_2013q3\n",
    "where quarter = 2 and year = '2013'\n",
    "group by employer\n",
    "'''\n",
    "emp_q2_df = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the table\n",
    "emp_q2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's merge it with employer_df\n",
    "employer_df = employer_df.merge(emp_q2_df, on = 'employer', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the new variable\n",
    "employer_df[['num_employed','num_employed_q2']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `num_employed_q2` has some missing values. This is probably because some employers are new in 2013Q3. Let's fill in these missing values with zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employer_df['num_employed_q2'] = employer_df['num_employed_q2'].fillna(0)\n",
    "\n",
    "employer_df['num_employed_q2'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have both `num_employed` and `num_employed_q2` in our DataFrame. Let's calculate employment growth rate based on the normalization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#growth rates of employment\n",
    "employer_df['emp_rate'] = 2 * (employer_df['num_employed'] - \n",
    "                               employer_df['num_employed_q2']) / (employer_df['num_employed'] +\n",
    "                                                                  employer_df['num_employed_q2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employer_df['emp_rate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separation Growth Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's calculate separataion growth rate. Similar to the employment growth rate, we will need the number of job separations for each employer in both 2013Q2 and 2013Q3. To find the number of employees that separated from their employer in 2013Q2(Q3), in practice, we take `employer` and `ssn_hash` entries from consecutive quarters and if a person is in the first but is not in the next quarter, we assume this individual was separated from their job. The process followed is this:\n",
    "- Find the `ssn_hash` and `employer` for every individual that had earnings in 2013Q2(Q3)\n",
    "- Find the `ssn_hash` and `employer` for every individual that had earnings in 2013Q3(Q4)\n",
    "- Left join 2013Q3 to 2013Q2 (2013Q3 to 2013Q4) to include an indicator (`q3` or `q4`) of whether they were employed in 2013Q3(Q4) (NULL if not). If the person showed in 2013Q2 but not 2013Q3, it implies this person left their employer during 2013Q2. \n",
    "- Count the amount of `ssn_hash` values per `employer` where the indicator (`q3` or `q4`) is NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people left their jobs in 2013Q2 by employer\n",
    "qry = '''\n",
    "select employer,count(distinct(ssn_hash)) as nsep_q2 from\n",
    "\t(select a.employer,a.ssn_hash,a.quarter as q2,b.quarter as q3 from\n",
    "    \t(select employer, ssn_hash, quarter from ada_20_osu.oh_2013q3\n",
    "     \twhere quarter = 2 and year = '2013') a\n",
    "\tleft join \n",
    "    \t(select employer, ssn_hash, quarter from ada_20_osu.oh_2013q3\n",
    "     \twhere quarter = 3 and year = '2013') b\n",
    "\ton a.employer=b.employer and a.ssn_hash=b.ssn_hash) c\n",
    "where c.q3 is null\n",
    "group by employer;\n",
    "'''\n",
    "nsep_q2_df = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsep_q2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people left their jobs in 2013Q3 by employer\n",
    "qry = '''\n",
    "select employer,count(distinct(ssn_hash)) as nsep_q3 from\n",
    "\t(select a.employer,a.ssn_hash,a.quarter,b.quarter as q4 from\n",
    "    \t(select employer, ssn_hash, quarter from ada_20_osu.oh_2013q3\n",
    "     \twhere quarter = 3 and year = '2013') a\n",
    "\tleft join \n",
    "    \t(select employer, ssn_hash, quarter from ada_20_osu.oh_2013q3\n",
    "     \twhere quarter = 4 and year = '2013') b\n",
    "\ton a.employer=b.employer and a.ssn_hash=b.ssn_hash) c\n",
    "where c.q4 is null\n",
    "group by employer;\n",
    "'''\n",
    "nsep_q3_df = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsep_q3_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, let's merge these two DataFrame with `employer_df` and fill in missing values with zero. Then we can use the normalization function to calculate separation growth rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames\n",
    "employer_df = employer_df.merge(nsep_q2_df, on = 'employer', how = 'left')\n",
    "\n",
    "employer_df = employer_df.merge(nsep_q3_df, on = 'employer', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with zero\n",
    "employer_df[['nsep_q2', 'nsep_q3']] = employer_df[['nsep_q2', 'nsep_q3']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking nulls\n",
    "employer_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#growth rates of job separation\n",
    "employer_df['sep_rate'] = 2 * (employer_df['nsep_q3'] - \n",
    "                               employer_df['nsep_q2']) / (employer_df['nsep_q2'] +\n",
    "                                                          employer_df['nsep_q3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see separation growth rate distribution\n",
    "employer_df['sep_rate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hire Growth Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to find the number of employees hired by each employer during 2013Q3, we follow a similar protocol as above. However, instead of counting those in the previous quarter who were not in the current quarter, we will count all those in the current quarter who did not have earnings for the same employer in the previous quarter. In other words, instead of using `LEFT JOIN`, we will be using `RIGHT JOIN` between `ssn_hash` by `employer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people got their jobs in 2013Q2, by employer\n",
    "qry = '''\n",
    "select employer,count(distinct(ssn_hash)) as nhire_q2 from\n",
    "\t(select b.employer,b.ssn_hash,a.quarter as q1,b.quarter as q2 from\n",
    "    \t(select employer, ssn_hash, quarter from ada_20_osu.oh_2013q3\n",
    "     \twhere quarter = 1 and year = '2013') a\n",
    "\tright join \n",
    "    \t(select employer, ssn_hash, quarter from ada_20_osu.oh_2013q3\n",
    "     \twhere quarter = 2 and year = '2013') b\n",
    "\ton a.employer=b.employer and a.ssn_hash=b.ssn_hash) c\n",
    "where c.q1 is null\n",
    "group by employer;\n",
    "'''\n",
    "nhire_q2_df = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhire_q2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people got their jobs in 2013Q3, by employer\n",
    "qry = '''\n",
    "select employer,count(distinct(ssn_hash)) as nhire_q3 from\n",
    "\t(select b.employer,b.ssn_hash,a.quarter as q2,b.quarter as q3 from\n",
    "    \t(select employer, ssn_hash, quarter from ada_20_osu.oh_2013q3\n",
    "     \twhere quarter = 2 and year = '2013') a\n",
    "\tright join \n",
    "    \t(select employer, ssn_hash, quarter from ada_20_osu.oh_2013q3\n",
    "     \twhere quarter = 3 and year = '2013') b\n",
    "\ton a.employer=b.employer and a.ssn_hash=b.ssn_hash) c\n",
    "where c.q2 is null\n",
    "group by employer;\n",
    "'''\n",
    "nhire_q3_df = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhire_q3_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames\n",
    "employer_df = employer_df.merge(nhire_q2_df, on = 'employer', how = 'left')\n",
    "\n",
    "employer_df = employer_df.merge(nhire_q3_df, on = 'employer', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with zero\n",
    "employer_df[['nhire_q2', 'nhire_q3']] = employer_df[['nhire_q2', 'nhire_q3']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking nulls\n",
    "employer_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#growth rates of new hires\n",
    "employer_df['hire_rate'] = 2 * (employer_df['nhire_q3'] - \n",
    "                                employer_df['nhire_q2']) / (employer_df['nhire_q2'] +\n",
    "                                                            employer_df['nhire_q3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see hiring growth rate distribution\n",
    "employer_df['hire_rate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employer_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 3: Find Growth Rates  </h3></font> \n",
    "\n",
    "Find hiring, separation, and employment growth rates for all employers in 2013Q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Data Manipulation\n",
    "\n",
    "At this point, we've created all of our desired measures. To get the dataset ready for clustering, we have to complete a few small tasks first, such as dropping unnecessary columns and filling in missing values if there are any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see df\n",
    "employer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let add full quarter employment and earnings statistics\n",
    "employer_df = employer_df.merge(full_quarter_df, on = 'employer', how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's not include columns that were just used for calculations\n",
    "emp = employer_df.drop(['year','quarter','nsep_q2','nsep_q3','nhire_q2','nhire_q3',\n",
    "                            'num_employed_q2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all nas\n",
    "emp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some variables have missing values. For the separation growth rate and full quarter statistics, we can just fill them in with zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert na's for full quarter to 0\n",
    "var_fill = ['sep_rate', 'hire_rate', 'full_quarter_num', 'full_quarter_earnings', 'full_quarter_avg_earnings']\n",
    "emp[var_fill] = emp[var_fill].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking nulls\n",
    "emp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some employers' NAICS codes in 2013Q3 are also incomplete. To properly capture the industries of these employers, we can see if they have non-missing NAICS codes in surrounding quarters (2013Q2 and 2013Q4), and if so, we can assume that the employer's industry did not change during 2013Q3. There will still be some employers with missing NAICS codes, but this will help to limit that number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all naics codes for employers who NAICS codes were missing in Q3 but in surrounding quarters\n",
    "qry = '''\n",
    "select distinct employer, naics_3_digit\n",
    "from ada_20_osu.oh_2013q3\n",
    "where employer in (\n",
    "select distinct(employer) from ada_20_osu.oh_2013q3 where naics_3_digit is null and quarter = 3) and naics_3_digit is not null\n",
    "order by employer\n",
    "'''\n",
    "naics_df = pd.read_sql(qry, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see naics_df\n",
    "naics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the `combine_first()` function to insert the NAICS codes from `naics_df` in surrounding quarters for the employers into the missing NAICS codes in `employer_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update naics codes where available\n",
    "employer_df = employer_df.set_index(\"employer\").combine_first(naics_df.set_index(\"employer\")).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are still missing values, we can just label them as \"missing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing industry code with \"missing\"\n",
    "emp['naics_3_digit'] = emp['naics_3_digit'].fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm no more null values\n",
    "emp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all naics codes in emp\n",
    "emp.naics_3_digit.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 4: Finalize Table  </h3></font> \n",
    "\n",
    "Finalize your table for employers in 2013Q2 by addressing missing NAICS codes as well as missing values for some of the other calculated measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our DataFrame is ready for the unsupervised machine learning model. Before we move on to the  [Unsupervised Machine Learning](Unsupervised_ML.ipynb) notebook, let's use `to_csv` to save it to a `.csv` file so that we can read it from another notebook. \n",
    "\n",
    "In the code below, you just need to change `YOURNAME` with your home folder name on ADRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write into csv for usage in clustering notebook\n",
    "emp.to_csv('/nfshome/YOURNAME/employer_all_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foster, Ian, Rayid Ghani, Ron S. Jarmin, Frauke Kreuter, and Julia Lane, eds. *Big data and social science: A practical guide to methods and tools.* crc Press, 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Davis, Steven J., and John Haltiwanger. \"Gross job creation, gross job destruction, and employment reallocation.\" *The Quarterly Journal of Economics* 107, no. 3 (1992): 819-863."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
